{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 32, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('data/train_data_with_samplefeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['winner_id'][0] == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'reverse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y9/_3j91y_j5_sb6xs2vpf3h9840000gn/T/ipykernel_53404/1192780523.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Create a sample DataFrame with 'date' and 'run' columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m data = {\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reverse'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame with 'date' and 'run' columns\n",
    "data = {\n",
    "    'date': pd.date_range(start='2023-01-01', periods=10, freq='D')[::-1],\n",
    "    'run': [50, 10, 20, 15, 6, 15, 40, 23, 22, 31]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ensure the DataFrame is sorted in descending order by 'date'\n",
    "df = df.sort_values(by='date', ascending=False)\n",
    "# print(df)\n",
    "# Reverse the 'run' series to apply EMA from the end\n",
    "reversed_run = df['run'].reverse\n",
    "\n",
    "# Calculate the EMA\n",
    "# reversed_ema = reversed_run.ewm(span=10, adjust=True).sum()\n",
    "reversed_ema = df['run'].ewm(span=10, adjust=True).sum().iloc[-1]\n",
    "\n",
    "# Reverse the EMA series back to the original order\n",
    "# df['EMA'] = reversed_ema#[::-1]\n",
    "\n",
    "# Display the DataFrame\n",
    "print(reversed_ema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-08</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  run\n",
       "0 2023-01-10   50\n",
       "1 2023-01-09   10\n",
       "2 2023-01-08   20\n",
       "3 2023-01-07   15\n",
       "4 2023-01-06    6\n",
       "5 2023-01-05   15\n",
       "6 2023-01-04   40\n",
       "7 2023-01-03   23\n",
       "8 2023-01-02   22\n",
       "9 2023-01-01   31"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/bowler_level_scorecard.csv')\n",
    "\n",
    "df['match_dt'] = pd.to_datetime(df['match_dt'])\n",
    "\n",
    "# df.set_index('match_dt', inplace=True)\n",
    "\n",
    "# # Resample to 6 months and 1 year, then count the matches\n",
    "# six_months = df.groupby('bowler_id').resample('6M').size()\n",
    "# one_year = df.groupby('bowler_id').resample('1Y').size()\n",
    "\n",
    "# # Reset the index to have a tidy DataFrame\n",
    "# six_months = six_months.reset_index(name='matches_6m')\n",
    "# one_year = one_year.reset_index(name='matches_1y')\n",
    "\n",
    "# # Average matches per player in 6 months\n",
    "# avg_matches_6m = six_months.groupby('bowler_id')['matches_6m'].mean().reset_index(name='avg_matches_6m')\n",
    "\n",
    "# # Average matches per player in 1 year\n",
    "# avg_matches_1y = one_year.groupby('bowler_id')['matches_1y'].mean().reset_index(name='avg_matches_1y')\n",
    "\n",
    "# # Combine the results\n",
    "# avg_matches = pd.merge(avg_matches_6m, avg_matches_1y, on='bowler_id')\n",
    "# print(avg_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     bowler_id  matches_2022\n",
      "0      34061.0            12\n",
      "1      37351.0             1\n",
      "2      41740.0             1\n",
      "3      49496.0             6\n",
      "4      55299.0            17\n",
      "..         ...           ...\n",
      "987  9373202.0             3\n",
      "988  9373209.0             1\n",
      "989  9373335.0             2\n",
      "990  9377969.0             1\n",
      "991  9382967.0             1\n",
      "\n",
      "[992 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for matches that occurred in 2022\n",
    "df_2022 = df[df['match_dt'].dt.year == 2022]\n",
    "\n",
    "# Group by 'player_id' and count the number of matches\n",
    "matches_2022 = df_2022.groupby('bowler_id').size().reset_index(name='matches_2022')\n",
    "\n",
    "print(matches_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    992.000000\n",
       "mean       5.792339\n",
       "std        6.212615\n",
       "min        1.000000\n",
       "25%        2.000000\n",
       "50%        3.000000\n",
       "75%        8.000000\n",
       "max       45.000000\n",
       "Name: matches_2022, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_2022['matches_2022'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/match_level_scorecard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['match_dt'] = pd.to_datetime(df['match_dt'])\n",
    "df = df[df['match_dt'].dt.year == 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of matches each team played\n",
    "team1_counts = df['team1_id'].value_counts()\n",
    "team2_counts = df['team2_id'].value_counts()\n",
    "\n",
    "# Combine the counts for each team\n",
    "total_counts = team1_counts.add(team2_counts, fill_value=0).astype(int)\n",
    "\n",
    "# Calculate the average number of matches played\n",
    "average_matches = total_counts.mean()\n",
    "\n",
    "# Calculate the median number of matches played\n",
    "median_matches = total_counts.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    131.000000\n",
       "mean      11.312977\n",
       "std        4.525286\n",
       "min        1.000000\n",
       "25%        8.500000\n",
       "50%       10.000000\n",
       "75%       14.000000\n",
       "max       26.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "team1_id\n",
       "55      38\n",
       "62      29\n",
       "48      28\n",
       "8056    24\n",
       "7727    23\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team1_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20       47\n",
       "27       41\n",
       "34       42\n",
       "41       44\n",
       "48       45\n",
       "         ..\n",
       "48936     9\n",
       "48943     8\n",
       "48950     8\n",
       "49650     7\n",
       "49657     8\n",
       "Name: count, Length: 174, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.413793103448278, 16.5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_matches, median_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_counts.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['team1_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df['team2_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.extend(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3378\n"
     ]
    }
   ],
   "source": [
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = set(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1689"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['team1_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.706896551724139"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1689/174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1.000000\n",
      "1     2.870551\n",
      "2     5.498959\n",
      "3     8.787122\n",
      "4    12.649634\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = [1, 2, 3, 4, 5]\n",
    "df = pd.DataFrame(data, columns=['value'])\n",
    "\n",
    "# Define the halflife\n",
    "halflife = 5\n",
    "\n",
    "# Calculate the exponentially weighted moving sum with the specified halflife\n",
    "ewm_sum = df['value'].ewm(halflife=halflife).sum()\n",
    "\n",
    "print(ewm_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10.0\n",
      "1    55.0\n",
      "Name: values, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'values': [10, 50]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Applying EWM with halflife=5\n",
    "ewm_sum = df['values'].ewm(halflife=1, adjust=True).sum()\n",
    "print(ewm_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average team composition similarity is 0.67\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "df = pd.read_csv('data/match_level_scorecard.csv')\n",
    "df['match_dt'] = pd.to_datetime(df['match_dt'])\n",
    "df = df[df['match_dt'].dt.year == 2022]\n",
    "\n",
    "# Function to calculate Jaccard similarity between two sets\n",
    "def jaccard_similarity(list1, list2):\n",
    "    set1, set2 = set(list1), set(list2)\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "# Process the dataframe\n",
    "def process_team_rosters(df):\n",
    "    team_variations = {}\n",
    "\n",
    "    for team_id in pd.concat([df['team1_id'], df['team2_id']]).unique():\n",
    "        team_matches = df[(df['team1_id'] == team_id) | (df['team2_id'] == team_id)]\n",
    "\n",
    "        # Extract the roster for each match\n",
    "        rosters = []\n",
    "        for idx, row in team_matches.iterrows():\n",
    "            if row['team1_id'] == team_id:\n",
    "                rosters.append(row['team1_roster_ids'].split(':'))\n",
    "            elif row['team2_id'] == team_id:\n",
    "                rosters.append(row['team2_roster_ids'].split(':'))\n",
    "\n",
    "        # Calculate pairwise Jaccard similarity for all matches\n",
    "        if len(rosters) > 1:\n",
    "            similarities = []\n",
    "            for roster1, roster2 in combinations(rosters, 2):\n",
    "                similarity = jaccard_similarity(roster1, roster2)\n",
    "                similarities.append(similarity)\n",
    "            team_variations[team_id] = sum(similarities) / len(similarities)\n",
    "        else:\n",
    "            team_variations[team_id] = 1.0  # If only one match, similarity is 1\n",
    "\n",
    "    # Calculate the average similarity across all teams\n",
    "    average_similarity = sum(team_variations.values()) / len(team_variations)\n",
    "    return average_similarity\n",
    "\n",
    "# Calculate the average team composition similarity\n",
    "average_similarity = process_team_rosters(df)\n",
    "print(f\"The average team composition similarity is {average_similarity:.2f}\")\n",
    "\n",
    "# Output: The average team composition similarity is 0.72\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of times a team plays with the same opponent: count    174.000000\n",
      "mean      10.689655\n",
      "std        4.865379\n",
      "min        1.000000\n",
      "25%        8.000000\n",
      "50%       10.000000\n",
      "75%       14.000000\n",
      "max       23.000000\n",
      "Name: match_combination, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "matches = pd.read_csv('data/match_level_scorecard.csv')\n",
    "# matches['match_dt'] = pd.to_datetime(matches['match_dt'])\n",
    "# matches = matches[matches['match_dt'].dt.year == 2021]\n",
    "\n",
    "# Concatenating team1_id and team2_id to represent each match combination\n",
    "matches['match_combination'] = matches.apply(lambda x: tuple(sorted([x['team1_id'], x['team2_id']])), axis=1)\n",
    "\n",
    "# Group by each team and count the number of unique opponents\n",
    "team1_opponents = matches.groupby('team1_id')['match_combination'].nunique()\n",
    "team2_opponents = matches.groupby('team2_id')['match_combination'].nunique()\n",
    "\n",
    "# Combine the counts from both teams\n",
    "total_opponents = team1_opponents.add(team2_opponents, fill_value=0)\n",
    "\n",
    "# Calculate the average number of opponents for each team\n",
    "average_opponents = total_opponents.describe()\n",
    "\n",
    "print(\"Average number of times a team plays with the same opponent:\", average_opponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ratio: 0.4120833823039705\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "matches = pd.read_csv('data/match_level_scorecard.csv')\n",
    "matches['match_dt'] = pd.to_datetime(matches['match_dt'])\n",
    "matches = matches[matches['match_dt'].dt.year == 2023]\n",
    "\n",
    "# Create a DataFrame to count matches for each team-opponent combination\n",
    "matches_team1 = matches[['team1_id', 'team2_id']]\n",
    "matches_team2 = matches[['team2_id', 'team1_id']]\n",
    "matches_team1.columns = ['team_id', 'opponent_id']\n",
    "matches_team2.columns = ['team_id', 'opponent_id']\n",
    "all_matches = pd.concat([matches_team1, matches_team2])\n",
    "\n",
    "# Calculate the total number of matches played by each team\n",
    "total_matches_per_team = all_matches.groupby('team_id').size()\n",
    "\n",
    "# Calculate the number of matches played by each team against each opponent\n",
    "matches_count = all_matches.groupby(['team_id', 'opponent_id']).size().reset_index(name='matches_count')\n",
    "\n",
    "# Find the maximum number of matches played against a single opponent for each team\n",
    "max_matches_per_team = matches_count.groupby('team_id')['matches_count'].max()\n",
    "\n",
    "# Calculate the ratio for each team\n",
    "ratios = max_matches_per_team / total_matches_per_team\n",
    "\n",
    "# Calculate the average of these ratios\n",
    "average_ratio = ratios.mean()\n",
    "\n",
    "print(\"Average ratio:\", average_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    131.000000\n",
       "mean       0.235011\n",
       "std        0.143019\n",
       "min        0.090909\n",
       "25%        0.153846\n",
       "50%        0.200000\n",
       "75%        0.272727\n",
       "max        1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ratio: 0.5315638177561768\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "matches = pd.read_csv('data/match_level_scorecard.csv')\n",
    "matches['match_dt'] = pd.to_datetime(matches['match_dt'])\n",
    "matches = matches[matches['match_dt'].dt.year == 2023]\n",
    "\n",
    "def compute_team_ratio(matches, team_id_column, opponent_id_column):\n",
    "    team_matches = matches.groupby([team_id_column, opponent_id_column]).size().reset_index(name='matches_count')\n",
    "    max_matches_per_team = team_matches.groupby(team_id_column)['matches_count'].max()\n",
    "    total_matches_per_team = matches.groupby(team_id_column).size()\n",
    "    return (max_matches_per_team / total_matches_per_team).mean()\n",
    "\n",
    "# Compute the ratio for both team1_id and team2_id\n",
    "ratio_team1 = compute_team_ratio(matches, 'team1_id', 'team2_id')\n",
    "ratio_team2 = compute_team_ratio(matches, 'team2_id', 'team1_id')\n",
    "\n",
    "# Calculate the overall average ratio\n",
    "average_ratio = (ratio_team1 + ratio_team2) / 2\n",
    "\n",
    "print(\"Average ratio:\", average_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of times a team plays with the same opponent: 1.7312002702213356\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "matches = pd.read_csv('data/match_level_scorecard.csv')\n",
    "\n",
    "# Creating a helper function to compute the average number of times a team plays with the same opponent\n",
    "def compute_avg_matches_against_opponent(matches, team_id_column, opponent_id_column):\n",
    "    team_matches = matches.groupby([team_id_column, opponent_id_column]).size().reset_index(name='matches_count')\n",
    "    avg_matches_per_team = team_matches.groupby(team_id_column)['matches_count'].mean()\n",
    "    return avg_matches_per_team.mean()\n",
    "\n",
    "# Compute the average number of times a team plays with the same opponent for both team1_id and team2_id\n",
    "avg_matches_team1 = compute_avg_matches_against_opponent(matches, 'team1_id', 'team2_id')\n",
    "avg_matches_team2 = compute_avg_matches_against_opponent(matches, 'team2_id', 'team1_id')\n",
    "\n",
    "# Calculate the overall average\n",
    "overall_avg_matches = (avg_matches_team1 + avg_matches_team2) / 2\n",
    "\n",
    "print(\"Average number of times a team plays with the same opponent:\", overall_avg_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "df = pd.read_csv('data/match_level_scorecard.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmatches\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseries_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39msize\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matches' is not defined"
     ]
    }
   ],
   "source": [
    "matches['series_name'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    set1, set2 = set(list1), set(list2)\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y9/_3j91y_j5_sb6xs2vpf3h9840000gn/T/ipykernel_89069/3443763967.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_series_relevant['team1_roster_ids'] = df_series_relevant['team1_roster_ids'].apply(lambda x: x.split(':'))\n",
      "/var/folders/y9/_3j91y_j5_sb6xs2vpf3h9840000gn/T/ipykernel_89069/3443763967.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_series_relevant['team2_roster_ids'] = df_series_relevant['team2_roster_ids'].apply(lambda x: x.split(':'))\n",
      "/var/folders/y9/_3j91y_j5_sb6xs2vpf3h9840000gn/T/ipykernel_89069/3443763967.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_series_relevant['team1_roster_ids'] = df_series_relevant['team1_roster_ids'].apply(lambda x: list(map(str, x)))\n",
      "/var/folders/y9/_3j91y_j5_sb6xs2vpf3h9840000gn/T/ipykernel_89069/3443763967.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_series_relevant['team2_roster_ids'] = df_series_relevant['team2_roster_ids'].apply(lambda x: list(map(str, x)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_name</th>\n",
       "      <th>avg_team1_similarity</th>\n",
       "      <th>avg_team2_similarity</th>\n",
       "      <th>average_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Nw Zd tr of Id</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Id tr of Ud Ss of Aa ad Wt Is</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Di Cs tr of Ud Ab Es</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aa tr of Nw Zd</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.891667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Si La tr of Wt Is</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Pb Ks tr of Ud Ab Es</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Pn tr of Ca</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Pn tr of Wt Is</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Qa Gs tr of Ud Ab Es</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Pn tr of Aa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       series_name  avg_team1_similarity  \\\n",
       "64                  Nw Zd tr of Id              0.888889   \n",
       "45   Id tr of Ud Ss of Aa ad Wt Is              0.833333   \n",
       "26            Di Cs tr of Ud Ab Es              1.000000   \n",
       "3                   Aa tr of Nw Zd              0.900000   \n",
       "103              Si La tr of Wt Is              0.888889   \n",
       "..                             ...                   ...   \n",
       "71            Pb Ks tr of Ud Ab Es              0.000000   \n",
       "75                     Pn tr of Ca              0.000000   \n",
       "80                  Pn tr of Wt Is              0.000000   \n",
       "83            Qa Gs tr of Ud Ab Es              0.000000   \n",
       "73                     Pn tr of Aa              0.000000   \n",
       "\n",
       "     avg_team2_similarity  average_similarity  \n",
       "64               1.000000            0.944444  \n",
       "45               1.000000            0.916667  \n",
       "26               0.833333            0.916667  \n",
       "3                0.883333            0.891667  \n",
       "103              0.888889            0.888889  \n",
       "..                    ...                 ...  \n",
       "71               0.000000            0.000000  \n",
       "75               0.000000            0.000000  \n",
       "80               0.000000            0.000000  \n",
       "83               0.000000            0.000000  \n",
       "73               0.000000            0.000000  \n",
       "\n",
       "[126 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract relevant columns including 'series_name'\n",
    "df_series_relevant = df[['series_name', 'team1_id', 'team2_id', 'team1_roster_ids', 'team2_roster_ids']]\n",
    "\n",
    "# Convert roster IDs from string to list of player IDs\n",
    "df_series_relevant['team1_roster_ids'] = df_series_relevant['team1_roster_ids'].apply(lambda x: x.split(':'))\n",
    "df_series_relevant['team2_roster_ids'] = df_series_relevant['team2_roster_ids'].apply(lambda x: x.split(':'))\n",
    "\n",
    "# Ensure player IDs are in the same format (e.g., strings) for consistency\n",
    "df_series_relevant['team1_roster_ids'] = df_series_relevant['team1_roster_ids'].apply(lambda x: list(map(str, x)))\n",
    "df_series_relevant['team2_roster_ids'] = df_series_relevant['team2_roster_ids'].apply(lambda x: list(map(str, x)))\n",
    "\n",
    "# Group matches by series and calculate Jaccard similarity for each team\n",
    "series_similarity_results = []\n",
    "\n",
    "for series, group in df_series_relevant.groupby('series_name'):\n",
    "    series_pairs_rosters = defaultdict(lambda: {'team1': [], 'team2': []})\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        pair = tuple(sorted([row['team1_id'], row['team2_id']]))\n",
    "        if row['team1_id'] == pair[0]:\n",
    "            series_pairs_rosters[pair]['team1'].append(row['team1_roster_ids'])\n",
    "            series_pairs_rosters[pair]['team2'].append(row['team2_roster_ids'])\n",
    "        else:\n",
    "            series_pairs_rosters[pair]['team1'].append(row['team2_roster_ids'])\n",
    "            series_pairs_rosters[pair]['team2'].append(row['team1_roster_ids'])\n",
    "    \n",
    "    team1_similarities = []\n",
    "    team2_similarities = []\n",
    "    \n",
    "    for pair, rosters in series_pairs_rosters.items():\n",
    "        team1_similarities.extend([jaccard_similarity(r1, r2) for r1, r2 in combinations(rosters['team1'], 2)])\n",
    "        team2_similarities.extend([jaccard_similarity(r1, r2) for r1, r2 in combinations(rosters['team2'], 2)])\n",
    "    \n",
    "    avg_team1_similarity = sum(team1_similarities) / len(team1_similarities) if team1_similarities else 0\n",
    "    avg_team2_similarity = sum(team2_similarities) / len(team2_similarities) if team2_similarities else 0\n",
    "    \n",
    "    series_similarity_results.append({\n",
    "        'series_name': series,\n",
    "        'avg_team1_similarity': avg_team1_similarity,\n",
    "        'avg_team2_similarity': avg_team2_similarity\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for easy viewing\n",
    "series_similarity_df = pd.DataFrame(series_similarity_results)\n",
    "series_similarity_df['average_similarity'] = series_similarity_df[['avg_team1_similarity', 'avg_team2_similarity']].mean(axis=1)\n",
    "series_similarity_df = series_similarity_df.sort_values(by='average_similarity', ascending=False)\n",
    "series_similarity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_team1_similarity</th>\n",
       "      <th>avg_team2_similarity</th>\n",
       "      <th>average_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.388353</td>\n",
       "      <td>0.409932</td>\n",
       "      <td>0.399142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.324821</td>\n",
       "      <td>0.344361</td>\n",
       "      <td>0.328686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.425370</td>\n",
       "      <td>0.445819</td>\n",
       "      <td>0.460740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.690653</td>\n",
       "      <td>0.698603</td>\n",
       "      <td>0.699695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_team1_similarity  avg_team2_similarity  average_similarity\n",
       "count            126.000000            126.000000          126.000000\n",
       "mean               0.388353              0.409932            0.399142\n",
       "std                0.324821              0.344361            0.328686\n",
       "min                0.000000              0.000000            0.000000\n",
       "25%                0.000000              0.000000            0.000000\n",
       "50%                0.425370              0.445819            0.460740\n",
       "75%                0.690653              0.698603            0.699695\n",
       "max                1.000000              1.000000            0.944444"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_similarity_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "df = pd.read_csv('data/test_data_with_samplefeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('processed_data/test_data_processed7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_id = df['match id']\n",
    "df2['match id'] = match_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('test_data_processed7_f.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "df = pd.read_csv('data/train_data_with_samplefeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['day/night match', 'day match', 'night match'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lighting'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
